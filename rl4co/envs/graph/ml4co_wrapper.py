"""
Generic Wrapper for ML4CO-Kit Graph Tasks as RL4CO Environments

This module provides wrapper classes that integrate ML4CO-Kit graph problem instances
into RL4CO's training framework without reimplementing the problem logic.

Supported Problems:
- MIS (Maximum Independent Set)
- MVC (Minimum Vertex Cover)
- MCL (Maximum Clique)
- MCUT (Maximum Cut)
"""

import torch
import numpy as np
from typing import Optional, Type, Dict, Any, List, Tuple, Callable
from tensordict import TensorDict

from rl4co.envs.common.base import RL4COEnvBase
from rl4co.utils.ops import gather_by_index


class ML4COGraphWrapper(RL4COEnvBase):
    """
    ML4CO-Kit Graph Problems çš„çœŸæ­£ Wrapper åŸºç±»
    
    è®¾è®¡åŸåˆ™ï¼š
    1. âœ… é‡ç”¨ ML4CO-Kit çš„ Generatorï¼ˆä¸é‡æ–°å®ç°å›¾ç”Ÿæˆï¼‰
    2. âœ… é‡ç”¨ ML4CO-Kit çš„ evaluate/check_constraintsï¼ˆä¸é‡æ–°å®ç°è¯„ä¼°ï¼‰
    3. âœ… é‡ç”¨ ML4CO-Kit çš„ Solverï¼ˆbaseline å¯¹æ¯”ï¼‰
    4. âœ… é‡ç”¨ ML4CO-Kit çš„ renderï¼ˆå¯è§†åŒ–ï¼‰
    5. âœ… åªåšæ ¼å¼è½¬æ¢ï¼šTensorDict â†” ML4CO Task
    6. âœ… åªå®ç° RL ç‰¹æœ‰é€»è¾‘ï¼ˆreset/step/rewardï¼‰
    """
    
    def __init__(
        self,
        ml4co_generator_class,    # ML4CO-Kit Generator ç±»
        ml4co_task_class,         # ML4CO-Kit Task ç±»
        ml4co_solver_class=None,  # ML4CO-Kit Solver ç±»ï¼ˆå¯é€‰ï¼‰
        generator_kwargs: dict = None,  # Generator çš„å‚æ•°
        solver_kwargs: dict = None,     # Solver çš„å‚æ•°
        **kwargs
    ):
        super().__init__(**kwargs)
        
        # 1. åˆ›å»º ML4CO-Kit Generatorï¼ˆé‡ç”¨ï¼ï¼‰
        generator_kwargs = generator_kwargs or {}
        self.ml4co_generator = ml4co_generator_class(**generator_kwargs)
        
        # 2. ä¿å­˜ Task ç±»ï¼ˆç”¨äºåˆ›å»ºå®ä¾‹ï¼‰
        self.ml4co_task_class = ml4co_task_class
        
        # 3. åˆ›å»º ML4CO-Kit Solverï¼ˆé‡ç”¨ï¼ï¼‰
        if ml4co_solver_class is not None:
            solver_kwargs = solver_kwargs or {}
            try:
                self.ml4co_solver = ml4co_solver_class(**solver_kwargs)
            except Exception as e:
                print(f"Warning: Failed to initialize solver: {e}")
                self.ml4co_solver = None
        else:
            self.ml4co_solver = None
        
        # 4. ä» Generator ä¸­æå–ç¯å¢ƒå‚æ•°
        self.num_nodes = getattr(self.ml4co_generator, 'nodes_num', 50)
        self.node_weighted = getattr(self.ml4co_generator, 'node_weighted', True)
        self.edge_weighted = getattr(self.ml4co_generator, 'edge_weighted', True)
        
        # 5. RL4CO å…¼å®¹æ€§ï¼ˆä¸ä½¿ç”¨ generatorï¼‰
        self.generator = None
    
    def generate_data(self, batch_size) -> TensorDict:
        """
        ç”Ÿæˆæ•°æ® - ä½¿ç”¨ ML4CO-Kit Generatorï¼ˆé‡ç”¨ï¼ï¼‰
        """
        # å¤„ç†å„ç§ batch_size æ ¼å¼
        if isinstance(batch_size, (tuple, list)):
            batch_size = batch_size[0]
        if isinstance(batch_size, torch.Tensor):
            batch_size = batch_size.item()
        batch_size = int(batch_size)
        
        # ğŸ”‘ å…³é”®æ”¹åŠ¨ï¼šä½¿ç”¨ ML4CO-Kit Generator ç”Ÿæˆ Tasksï¼ˆé‡ç”¨ï¼ï¼‰
        tasks = [self.ml4co_generator.generate() for _ in range(batch_size)]
        
        # æ ¼å¼è½¬æ¢ï¼šML4CO Task â†’ TensorDict
        return self._tasks_to_tensordict(tasks)
    
    def _tasks_to_tensordict(self, tasks: List) -> TensorDict:
        """
        æ ¼å¼è½¬æ¢ï¼šML4CO Task â†’ TensorDict
        è¿™æ˜¯ Wrapper çš„æ ¸å¿ƒå·¥ä½œï¼šæ ¼å¼é€‚é…
        """
        batch_size = len(tasks)
        
        edge_indices = []
        nodes_weights = []
        edge_nums = []
        
        for task in tasks:
            # ä» ML4CO-Kit Task ä¸­æå–æ•°æ®
            edge_index = task.edge_index  # [2, num_edges]
            edge_indices.append(torch.from_numpy(edge_index).long())
            edge_nums.append(edge_index.shape[1])
            
            # èŠ‚ç‚¹æƒé‡
            if self.node_weighted and task.nodes_weight is not None:
                nodes_weights.append(torch.from_numpy(task.nodes_weight).float())
            else:
                # é»˜è®¤æƒé‡ä¸º 1
                nodes_weights.append(torch.ones(task.nodes_num, dtype=torch.float32))
        
        # Pad edge_index to the same length (max_edges)
        max_edges = max(edge_nums)
        padded_edge_indices = []
        for edge_idx, num_edges in zip(edge_indices, edge_nums):
            if num_edges < max_edges:
                # Pad with -1 (invalid edge marker)
                padding = torch.full((2, max_edges - num_edges), -1, dtype=torch.long)
                edge_idx = torch.cat([edge_idx, padding], dim=1)
            padded_edge_indices.append(edge_idx)
        
        td = TensorDict({
            "edge_index": torch.stack(padded_edge_indices).to(self.device),
            "nodes_weight": torch.stack(nodes_weights).to(self.device),
            "nodes_num": torch.full((batch_size,), self.num_nodes, 
                                   dtype=torch.long, device=self.device),
            "edge_nums": torch.tensor(edge_nums, dtype=torch.long, device=self.device)
        }, batch_size=[batch_size])
        
        return td
    
    def reset(self, td: Optional[TensorDict] = None, batch_size=None) -> TensorDict:
        """é‡ç½®ç¯å¢ƒï¼ˆé‡å†™ä»¥é¿å…è°ƒç”¨ generatorï¼‰"""
        if batch_size is None:
            batch_size = self.batch_size if td is None else td.batch_size
        
        # æ ‡å‡†åŒ– batch_size æ ¼å¼
        if isinstance(batch_size, (tuple, list)):
            batch_size_int = batch_size[0] if isinstance(batch_size[0], int) else batch_size[0].item()
        elif isinstance(batch_size, torch.Tensor):
            batch_size_int = batch_size.item()
        else:
            batch_size_int = int(batch_size)
        
        if td is None or "edge_index" not in td:
            td = self.generate_data(batch_size=batch_size)
        
        # åˆå§‹åŒ–çŠ¶æ€ï¼ˆä¼ å…¥æ ‡å‡†åŒ–çš„æ•´æ•° batch_sizeï¼‰
        td = self._init_state(td, batch_size_int)
        
        return td
    
    def _reset(self, td: TensorDict = None, batch_size=None) -> TensorDict:
        """å†…éƒ¨ resetï¼ˆå…¼å®¹çˆ¶ç±»ï¼‰"""
        return self.reset(td, batch_size)
    
    def _init_state(self, td: TensorDict, batch_size) -> TensorDict:
        """åˆå§‹åŒ– RL çŠ¶æ€ï¼ˆç”±å­ç±»å®ç°å…·ä½“é€»è¾‘ï¼‰"""
        raise NotImplementedError
    
    def _step(self, td: TensorDict) -> TensorDict:
        """æ‰§è¡Œä¸€æ­¥åŠ¨ä½œï¼ˆç”±å­ç±»å®ç°ï¼‰"""
        raise NotImplementedError
    
    def _get_reward(self, td: TensorDict, actions=None) -> torch.Tensor:
        """
        è®¡ç®—å¥–åŠ± - ä½¿ç”¨ ML4CO-Kit çš„ evaluate æ–¹æ³•ï¼ˆé‡ç”¨ï¼ï¼‰
        """
        # æ ¼å¼è½¬æ¢ï¼šTensorDict â†’ ML4CO Tasks
        tasks = self._tensordict_to_tasks(td)
        
        # ğŸ”‘ å…³é”®æ”¹åŠ¨ï¼šä½¿ç”¨ ML4CO-Kit çš„ evaluate æ–¹æ³•ï¼ˆé‡ç”¨ï¼ï¼‰
        rewards = []
        for task in tasks:
            if task.sol is not None:
                try:
                    obj_val = task.evaluate(task.sol)
                    # æ ¹æ®æœ€å¤§åŒ–/æœ€å°åŒ–è°ƒæ•´ç¬¦å·ï¼ˆRL4CO ç»Ÿä¸€ä¸ºæœ€å¤§åŒ–ï¼‰
                    reward = obj_val if not task.minimize else -obj_val
                    rewards.append(float(reward))
                except:
                    rewards.append(0.0)
            else:
                rewards.append(0.0)
        
        return torch.tensor(rewards, dtype=torch.float32, device=self.device)
    
    def check_solution_validity(self, td: TensorDict, actions: torch.Tensor) -> None:
        """
        æ£€æŸ¥è§£çš„æœ‰æ•ˆæ€§ - ä½¿ç”¨ ML4CO-Kit çš„ check_constraintsï¼ˆé‡ç”¨ï¼ï¼‰
        """
        tasks = self._tensordict_to_tasks(td)
        
        # ğŸ”‘ å…³é”®æ”¹åŠ¨ï¼šä½¿ç”¨ ML4CO-Kit çš„ check_constraints æ–¹æ³•ï¼ˆé‡ç”¨ï¼ï¼‰
        for i, task in enumerate(tasks):
            if task.sol is not None:
                is_valid = task.check_constraints(task.sol)
                if not is_valid:
                    # ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°è¯¦ç»†é”™è¯¯
                    selected_nodes = np.where(task.sol == 1)[0]
                    adj_matrix = task.to_adj_matrix()
                    np.fill_diagonal(adj_matrix, 0)
                    conflicts = adj_matrix[selected_nodes][:, selected_nodes]
                    conflict_pairs = np.argwhere(conflicts)
                    
                    print(f"âš ï¸  Warning: Invalid solution for instance {i}")
                    print(f"   - Selected nodes: {selected_nodes.tolist()}")
                    print(f"   - Num selected: {len(selected_nodes)}")
                    print(f"   - Conflict pairs (within selected): {conflict_pairs.tolist() if len(conflict_pairs) > 0 else 'None'}")
                    if len(conflict_pairs) > 0:
                        for p1, p2 in conflict_pairs[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªå†²çª
                            node1, node2 = selected_nodes[p1], selected_nodes[p2]
                            print(f"   - Conflict: node {node1} and node {node2} are adjacent but both selected!")
    
    def _tensordict_to_tasks(self, td: TensorDict) -> List:
        """
        æ ¼å¼è½¬æ¢ï¼šTensorDict â†’ ML4CO Tasks
        è¿™æ˜¯ Wrapper çš„æ ¸å¿ƒå·¥ä½œï¼šæ ¼å¼é€‚é…
        """
        batch_size = td.batch_size[0]
        tasks = []
        
        for i in range(batch_size):
            # åˆ›å»º ML4CO-Kit Task å®ä¾‹
            task = self.ml4co_task_class(
                node_weighted=self.node_weighted,
                precision=np.float32
            )
            
            # æå–æ•°æ®ï¼ˆç§»é™¤ paddingï¼‰
            edge_index = td["edge_index"][i].cpu().numpy()
            valid_mask = edge_index[0] >= 0
            valid_edge_index = edge_index[:, valid_mask]
            
            nodes_weight = None
            if self.node_weighted:
                nodes_weight = td["nodes_weight"][i].cpu().numpy()
            
            # ğŸ”‘ å…³é”®æ”¹åŠ¨ï¼šä½¿ç”¨ ML4CO-Kit çš„ from_data æ–¹æ³•ï¼ˆé‡ç”¨ï¼ï¼‰
            task.from_data(
                edge_index=valid_edge_index,
                nodes_weight=nodes_weight
            )
            
            # å¦‚æœæœ‰è§£ï¼Œè®¾ç½®è§£
            if "selected" in td:
                solution = td["selected"][i].cpu().numpy().astype(np.int32)
                task.sol = solution
                
                # ä½¿ç”¨ ML4CO-Kit çš„ evaluate æ–¹æ³•
                try:
                    task.obj_val = task.evaluate(solution)
                except:
                    pass
            
            tasks.append(task)
        
        return tasks
    
    def solve_with_ml4co(
        self, 
        td: TensorDict, 
        verbose: bool = False,
        return_solutions: bool = False,
        time_limit: float = None
    ) -> dict:
        """
        ä½¿ç”¨ ML4CO-Kit Solver æ±‚è§£ï¼ˆé‡ç”¨ï¼ï¼‰
        
        Args:
            td: TensorDict with problem instances
            verbose: Print detailed solving information
            return_solutions: Return the actual solutions (not just obj values)
            time_limit: Time limit per instance (if solver supports)
        
        Returns:
            dict: {
                'obj_vals': List of objective values,
                'solutions': List of solutions (if return_solutions=True),
                'solve_times': List of solving times per instance,
                'success_rate': Percentage of successfully solved instances,
                'statistics': {mean, std, min, max},
            }
        """
        if self.ml4co_solver is None:
            raise ValueError(
                f"ML4CO Solver is not initialized for {self.name}. "
                f"Please install the required solver."
            )
        
        import time
        
        # æ ¼å¼è½¬æ¢ï¼šTensorDict â†’ ML4CO Tasks
        tasks = self._tensordict_to_tasks(td)
        batch_size = len(tasks)
        
        if verbose:
            print(f"\n{'='*70}")
            print(f"ML4CO-Kit Solver: {type(self.ml4co_solver).__name__}")
            print(f"Problem: {self.name.upper()}")
            print(f"Instances: {batch_size}")
            if time_limit:
                print(f"Time limit: {time_limit}s per instance")
            print(f"{'='*70}\n")
        
        # æ±‚è§£æ‰€æœ‰å®ä¾‹
        obj_vals = []
        solutions = []
        solve_times = []
        failed_count = 0
        
        for i, task in enumerate(tasks):
            start_time = time.time()
            try:
                # ä½¿ç”¨ ML4CO-Kit Solver æ±‚è§£
                solved_task = self.ml4co_solver.solve(task)
                solve_time = time.time() - start_time
                
                # æå–ç»“æœ
                obj_val = solved_task.obj_val if hasattr(solved_task, 'obj_val') else 0.0
                obj_vals.append(float(obj_val))
                solve_times.append(solve_time)
                
                if return_solutions:
                    solutions.append(solved_task.sol if hasattr(solved_task, 'sol') else None)
                
                if verbose and (i + 1) % max(1, batch_size // 10) == 0:
                    print(f"  Progress: {i+1}/{batch_size} | "
                          f"Obj: {obj_val:.4f} | Time: {solve_time:.3f}s")
                          
            except Exception as e:
                solve_time = time.time() - start_time
                solve_times.append(solve_time)
                obj_vals.append(0.0)
                solutions.append(None)
                failed_count += 1
                
                if verbose:
                    print(f"  âš ï¸  Instance {i} failed: {e}")
        
        # ç»Ÿè®¡ç»“æœ
        success_rate = (batch_size - failed_count) / batch_size * 100
        
        results = {
            'obj_vals': obj_vals,
            'solve_times': solve_times,
            'success_rate': success_rate,
            'statistics': {
                'mean': float(np.mean(obj_vals)) if obj_vals else 0.0,
                'std': float(np.std(obj_vals)) if obj_vals else 0.0,
                'min': float(np.min(obj_vals)) if obj_vals else 0.0,
                'max': float(np.max(obj_vals)) if obj_vals else 0.0,
            },
            'timing': {
                'mean_per_instance': float(np.mean(solve_times)) if solve_times else 0.0,
                'total': float(np.sum(solve_times)) if solve_times else 0.0,
            },
            'failed_count': failed_count,
        }
        
        if return_solutions:
            results['solutions'] = solutions
        
        if verbose:
            print(f"\n{'='*70}")
            print(f"Results Summary")
            print(f"{'='*70}")
            print(f"Success rate: {success_rate:.1f}% ({batch_size-failed_count}/{batch_size})")
            print(f"\nObjective values:")
            print(f"  Mean: {results['statistics']['mean']:.4f}")
            print(f"  Std:  {results['statistics']['std']:.4f}")
            print(f"  Min:  {results['statistics']['min']:.4f}")
            print(f"  Max:  {results['statistics']['max']:.4f}")
            print(f"\nSolving time:")
            print(f"  Mean per instance: {results['timing']['mean_per_instance']:.3f}s")
            print(f"  Total: {results['timing']['total']:.2f}s")
            print(f"{'='*70}\n")
        
        return results
    
    def render(self, td: TensorDict, idx: int = 0, save_path: str = None):
        """
        å¯è§†åŒ– - ä½¿ç”¨ ML4CO-Kit çš„ render æ–¹æ³•ï¼ˆé‡ç”¨ï¼ï¼‰
        """
        # æ ¼å¼è½¬æ¢ï¼šTensorDict â†’ ML4CO Task
        tasks = self._tensordict_to_tasks(td)
        task = tasks[idx]
        
        # ğŸ”‘ å…³é”®æ”¹åŠ¨ï¼šä½¿ç”¨ ML4CO-Kit çš„ render æ–¹æ³•ï¼ˆé‡ç”¨ï¼ï¼‰
        import pathlib
        if save_path is None:
            save_path = f"{self.name}_{idx}.png"
        
        task.render(save_path=pathlib.Path(save_path))
        print(f"Rendered to {save_path}")


class MISEnvWrapper(ML4COGraphWrapper):
    """
    Maximum Independent Set (MIS) Environment Wrapper
    
    ç›®æ ‡ï¼šé€‰æ‹©æœ€å¤§çš„ç‹¬ç«‹é›†ï¼ˆèŠ‚ç‚¹é›†åˆä¸­ä»»æ„ä¸¤ä¸ªèŠ‚ç‚¹ä¸ç›¸é‚»ï¼‰
    
    è§‚å¯Ÿç©ºé—´:
        - edge_index: è¾¹ç´¢å¼• [batch, 2, num_edges]
        - nodes_weight: èŠ‚ç‚¹æƒé‡ [batch, num_nodes]
        - selected: å·²é€‰æ‹©çš„èŠ‚ç‚¹ [batch, num_nodes] (binary)
        - available: å¯é€‰èŠ‚ç‚¹ [batch, num_nodes] (binary)
    
    åŠ¨ä½œç©ºé—´:
        - é€‰æ‹©ä¸€ä¸ªå¯ç”¨èŠ‚ç‚¹åŠ å…¥ç‹¬ç«‹é›†
    
    å¥–åŠ±:
        - æœ€å¤§åŒ–é€‰ä¸­èŠ‚ç‚¹çš„æƒé‡ä¹‹å’Œ
    """
    
    name = "mis"
    
    def __init__(
        self,
        num_nodes: int = 50,
        graph_type: str = 'erdos_renyi',
        edge_prob: float = 0.15,
        node_weighted: bool = False,
        **kwargs
    ):
        # å¯¼å…¥ ML4CO-Kit çš„ç±»
        from ml4co_kit.generator.graph.mis import MISGenerator, GRAPH_TYPE
        from ml4co_kit.task.graph.mis import MISTask
        
        # Solverï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            from ml4co_kit.solver.kamis import KaMISSolver
            solver_class = KaMISSolver
        except ImportError:
            print("Warning: KaMIS solver not available")
            solver_class = None
        
        # æ˜ å°„å›¾ç±»å‹
        graph_type_map = {
            'erdos_renyi': GRAPH_TYPE.ER,
            'barabasi_albert': GRAPH_TYPE.BA,
            'watts_strogatz': GRAPH_TYPE.WS,
        }
        
        # Generator å‚æ•°ï¼ˆä½¿ç”¨ ML4CO-Kit çš„ APIï¼‰
        generator_kwargs = {
            'distribution_type': graph_type_map.get(graph_type, GRAPH_TYPE.ER),
            'nodes_num_scale': (num_nodes, num_nodes),  # å›ºå®šèŠ‚ç‚¹æ•°
            'er_prob': edge_prob,
            'node_weighted': node_weighted,
        }
        
        # è°ƒç”¨çˆ¶ç±»ï¼ˆä½¿ç”¨ ML4CO-Kit Generatorï¼ï¼‰
        super().__init__(
            ml4co_generator_class=MISGenerator,
            ml4co_task_class=MISTask,
            ml4co_solver_class=solver_class,
            generator_kwargs=generator_kwargs,
            **kwargs
        )
    
    def _init_state(self, td: TensorDict, batch_size: int) -> TensorDict:
        """åˆå§‹åŒ–çŠ¶æ€ï¼ˆbatch_size å·²ç»æ˜¯æ•´æ•°ï¼‰"""
        # åˆå§‹åŒ–ï¼šéœ€è¦è¦†ç›–æ‰€æœ‰è¾¹
        num_edges = td["edge_index"].shape[2] // 2  # æ— å‘å›¾ï¼Œé™¤ä»¥2
        
        td.update({
            "selected": torch.zeros(
                batch_size, self.num_nodes, 
                dtype=torch.bool, 
                device=self.device
            ),
            "available": torch.ones(
                batch_size, self.num_nodes, 
                dtype=torch.bool, 
                device=self.device
            ),
            "i": torch.zeros(batch_size, dtype=torch.int64, device=self.device),
            "done": torch.zeros(batch_size, dtype=torch.bool, device=self.device),
            "current_node": torch.zeros(batch_size, dtype=torch.long, device=self.device),
            "action_mask": torch.ones(
                batch_size, self.num_nodes,
                dtype=torch.bool,
                device=self.device
            ),
        })
        return td
    
    def _step(self, td: TensorDict) -> TensorDict:
        """æ‰§è¡Œä¸€æ­¥ï¼šé€‰æ‹©ä¸€ä¸ªèŠ‚ç‚¹"""
        selected_node = td["action"]
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šåªæ›´æ–°æœªå®Œæˆçš„å®ä¾‹
        prev_done = td["done"]  # ä¹‹å‰çš„ done çŠ¶æ€
        
        # æ›´æ–° selectedï¼ˆåªæ›´æ–°æœªå®Œæˆçš„å®ä¾‹ï¼‰
        selected_mask = td["selected"].clone()
        # åªæœ‰æœªå®Œæˆçš„å®ä¾‹æ‰çœŸæ­£é€‰æ‹©èŠ‚ç‚¹
        selected_mask[~prev_done] = selected_mask[~prev_done].scatter(
            -1, 
            selected_node[~prev_done].unsqueeze(-1), 
            1
        )
        
        # æ›´æ–° availableï¼šç§»é™¤é€‰ä¸­èŠ‚ç‚¹åŠå…¶æ‰€æœ‰é‚»å±…ï¼ˆåªå¯¹æœªå®Œæˆçš„å®ä¾‹ï¼‰
        available_mask = td["available"].clone()
        if (~prev_done).any():
            # åªæ›´æ–°æœªå®Œæˆçš„å®ä¾‹çš„ available
            updated_available = self._update_available(
                td["edge_index"][~prev_done], 
                selected_node[~prev_done],
                td["available"][~prev_done]
            )
            available_mask[~prev_done] = updated_available
        
        # è®¡ç®—å³æ—¶å¥–åŠ±ï¼ˆåªå¯¹æœªå®Œæˆçš„å®ä¾‹ï¼‰
        reward = torch.zeros_like(prev_done, dtype=torch.float32)
        if (~prev_done).any():
            reward[~prev_done] = gather_by_index(
                td["nodes_weight"][~prev_done], 
                selected_node[~prev_done]
            )
        
        # æ£€æŸ¥å®Œæˆï¼ˆåˆå¹¶ä¹‹å‰çš„ done çŠ¶æ€ï¼‰
        done = prev_done | (~available_mask.any(-1))
        
        # å½“ done æ—¶ï¼Œä¸ºäº†é¿å… decoder é”™è¯¯ï¼Œæˆ‘ä»¬éœ€è¦è‡³å°‘ä¿ç•™ä¸€ä¸ªå¯ç”¨åŠ¨ä½œ
        action_mask = available_mask.clone()
        action_mask[done] = True  # å½“ done æ—¶ï¼Œè®¾ç½®ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä¸ºå¯ç”¨ï¼ˆè™šæ‹ŸåŠ¨ä½œï¼‰
        action_mask[done, 1:] = False  # åªä¿ç•™ç¬¬ä¸€ä¸ªèŠ‚ç‚¹å¯ç”¨
        
        td.update({
            "selected": selected_mask,
            "available": available_mask,
            "reward": reward,
            "done": done,
            "i": td["i"] + 1,
            "current_node": selected_node,
            "action_mask": action_mask,
        })
        
        return td
    
    def _update_available(self, edge_index, selected_nodes, available):
        """æ›´æ–°å¯ç”¨èŠ‚ç‚¹ï¼šç§»é™¤é€‰ä¸­èŠ‚ç‚¹åŠå…¶é‚»å±…"""
        batch_size = edge_index.shape[0]
        available = available.clone()
        
        for b in range(batch_size):
            node_idx = selected_nodes[b].item()
            # æ‰¾åˆ°è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰é‚»å±…
            edges = edge_index[b]  # [2, num_edges]
            
            # è¿‡æ»¤æ‰ padding çš„è¾¹ï¼ˆ-1ï¼‰
            valid_mask = edges[0] >= 0
            valid_edges = edges[:, valid_mask]
            
            # ğŸ”§ ä¿®å¤ï¼šå¯¹äºæ— å‘å›¾ï¼Œéœ€è¦æŸ¥æ‰¾ä¸¤ä¸ªæ–¹å‘çš„è¾¹
            # æ–¹å‘1: edge_index[0] == node_idx çš„ edge_index[1]
            neighbors_1 = valid_edges[1, valid_edges[0] == node_idx]
            # æ–¹å‘2: edge_index[1] == node_idx çš„ edge_index[0]
            neighbors_2 = valid_edges[0, valid_edges[1] == node_idx]
            
            # åˆå¹¶ä¸¤ä¸ªæ–¹å‘çš„é‚»å±…
            neighbors = torch.cat([neighbors_1, neighbors_2]).unique()
            
            # ç§»é™¤èŠ‚ç‚¹æœ¬èº«å’Œæ‰€æœ‰é‚»å±…
            available[b, node_idx] = False
            if len(neighbors) > 0:
                available[b, neighbors] = False
        
        return available
    
    def _set_task_data(self, task, edge_index, nodes_weight, td, idx):
        """è®¾ç½® MISTask æ•°æ®"""
        # ç§»é™¤ padding çš„è¾¹ï¼ˆ-1ï¼‰
        valid_mask = edge_index[0] >= 0
        valid_edge_index = edge_index[:, valid_mask]
        
        # ä½¿ç”¨ from_data æ–¹æ³•
        task.from_data(
            nodes_num=self.num_nodes,
            edge_index=valid_edge_index,
            nodes_weight=nodes_weight if self.node_weighted else None
        )
        
        # å¦‚æœæœ‰è§£ï¼Œè®¾ç½®è§£
        if "selected" in td:
            solution = td["selected"][idx].cpu().numpy().astype(np.int32)
            task.sol = solution
            try:
                task.obj_val = task.evaluate(solution)
            except:
                pass
    
    @staticmethod
    def render(td: TensorDict, actions=None, ax=None):
        """å¯è§†åŒ–"""
        import matplotlib.pyplot as plt
        import networkx as nx
        
        if ax is None:
            _, ax = plt.subplots(figsize=(8, 8))
        
        # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
        edge_index = td["edge_index"][0].cpu().numpy()
        selected = td.get("selected", None)
        if selected is not None:
            selected = selected[0].cpu().numpy()
        
        # æ„å»º NetworkX å›¾
        G = nx.Graph()
        G.add_nodes_from(range(td["nodes_num"][0].item()))
        edges = [(edge_index[0, i], edge_index[1, i]) 
                 for i in range(edge_index.shape[1]) if edge_index[0, i] < edge_index[1, i]]
        G.add_edges_from(edges)
        
        # å¸ƒå±€
        pos = nx.spring_layout(G, k=1, iterations=50)
        
        # èŠ‚ç‚¹é¢œè‰²
        if selected is not None:
            node_colors = ['orange' if selected[i] else 'lightblue' 
                          for i in range(len(G.nodes()))]
            title = f"MIS Solution (Size: {selected.sum()})"
        else:
            node_colors = 'lightblue'
            title = "MIS Problem Instance"
        
        # ç»˜åˆ¶
        nx.draw(G, pos, node_color=node_colors, with_labels=True, 
               node_size=500, font_size=10, font_weight='bold', ax=ax)
        ax.set_title(title)


class MVCEnvWrapper(ML4COGraphWrapper):
    """
    Minimum Vertex Cover (MVC) Environment Wrapper
    
    ç›®æ ‡ï¼šé€‰æ‹©æœ€å°çš„é¡¶ç‚¹è¦†ç›–ï¼ˆæ‰€æœ‰è¾¹è‡³å°‘æœ‰ä¸€ä¸ªç«¯ç‚¹è¢«é€‰ä¸­ï¼‰
    
    MVC æ˜¯ MIS çš„å¯¹å¶é—®é¢˜ï¼šV \ MVC(G) = MIS(G)
    """
    
    name = "mvc"
    
    def __init__(
        self,
        num_nodes: int = 50,
        graph_type: str = 'erdos_renyi',
        edge_prob: float = 0.15,
        node_weighted: bool = False,
        **kwargs
    ):
        # å¯¼å…¥ ML4CO-Kit çš„ç±»
        from ml4co_kit.generator.graph.mvc import MVCGenerator, GRAPH_TYPE
        from ml4co_kit.task.graph.mvc import MVCTask
        
        # æ˜ å°„å›¾ç±»å‹
        graph_type_map = {
            'erdos_renyi': GRAPH_TYPE.ER,
            'barabasi_albert': GRAPH_TYPE.BA,
            'watts_strogatz': GRAPH_TYPE.WS,
        }
        
        # Generator å‚æ•°
        generator_kwargs = {
            'distribution_type': graph_type_map.get(graph_type, GRAPH_TYPE.ER),
            'nodes_num_scale': (num_nodes, num_nodes),
            'er_prob': edge_prob,
            'node_weighted': node_weighted,
        }
        
        # è°ƒç”¨çˆ¶ç±»ï¼ˆä½¿ç”¨ ML4CO-Kit Generatorï¼ï¼‰
        super().__init__(
            ml4co_generator_class=MVCGenerator,
            ml4co_task_class=MVCTask,
            ml4co_solver_class=None,
            generator_kwargs=generator_kwargs,
            **kwargs
        )
    
    def _init_state(self, td: TensorDict, batch_size) -> TensorDict:
        """åˆå§‹åŒ–çŠ¶æ€"""
        # å¤„ç†å„ç§ batch_size æ ¼å¼
        if isinstance(batch_size, (tuple, list)):
            batch_size = batch_size[0]
        if isinstance(batch_size, torch.Tensor):
            batch_size = batch_size.item()
        batch_size = int(batch_size)
        
        # åˆå§‹åŒ–ï¼šéœ€è¦è¦†ç›–æ‰€æœ‰è¾¹
        num_edges = td["edge_index"].shape[2] // 2  # æ— å‘å›¾ï¼Œé™¤ä»¥2
        
        td.update({
            "selected": torch.zeros(
                batch_size, self.num_nodes, 
                dtype=torch.bool, 
                device=self.device
            ),
            "covered_edges": torch.zeros(
                batch_size, num_edges, 
                dtype=torch.bool, 
                device=self.device
            ),
            "i": torch.zeros(batch_size, dtype=torch.int64, device=self.device),
        })
        return td
    
    def _step(self, td: TensorDict) -> TensorDict:
        """æ‰§è¡Œä¸€æ­¥ï¼šé€‰æ‹©ä¸€ä¸ªèŠ‚ç‚¹åŠ å…¥é¡¶ç‚¹è¦†ç›–"""
        selected_node = td["action"]
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šåªæ›´æ–°æœªå®Œæˆçš„å®ä¾‹
        prev_done = td["done"]
        
        # æ›´æ–° selectedï¼ˆåªæ›´æ–°æœªå®Œæˆçš„å®ä¾‹ï¼‰
        selected_mask = td["selected"].clone()
        if (~prev_done).any():
            selected_mask[~prev_done] = selected_mask[~prev_done].scatter(
                -1, 
                selected_node[~prev_done].unsqueeze(-1), 
                1
            )
        
        # æ›´æ–° covered_edgesï¼šæ ‡è®°è¯¥èŠ‚ç‚¹è¦†ç›–çš„è¾¹ï¼ˆåªå¯¹æœªå®Œæˆçš„å®ä¾‹ï¼‰
        covered_edges = td["covered_edges"].clone()
        if (~prev_done).any():
            updated_covered = self._update_covered_edges(
                td["edge_index"][~prev_done],
                selected_node[~prev_done],
                td["covered_edges"][~prev_done]
            )
            covered_edges[~prev_done] = updated_covered
        
        # è®¡ç®—æƒ©ç½šï¼ˆæœ€å°åŒ–é—®é¢˜ï¼Œæ¯é€‰ä¸€ä¸ªèŠ‚ç‚¹éƒ½æ˜¯ä»£ä»·ï¼‰
        reward = torch.zeros_like(prev_done, dtype=torch.float32)
        if (~prev_done).any():
            reward[~prev_done] = -gather_by_index(
                td["nodes_weight"][~prev_done], 
                selected_node[~prev_done]
            )
        
        # æ£€æŸ¥å®Œæˆï¼šæ‰€æœ‰è¾¹éƒ½è¢«è¦†ç›–ï¼ˆåˆå¹¶ä¹‹å‰çš„ done çŠ¶æ€ï¼‰
        done = prev_done | covered_edges.all(-1)
        
        td.update({
            "selected": selected_mask,
            "covered_edges": covered_edges,
            "reward": reward,
            "done": done,
            "i": td["i"] + 1,
        })
        
        return td
    
    def _update_covered_edges(self, edge_index, selected_nodes, covered_edges):
        """æ›´æ–°å·²è¦†ç›–çš„è¾¹"""
        batch_size = edge_index.shape[0]
        covered_edges = covered_edges.clone()
        
        for b in range(batch_size):
            node_idx = selected_nodes[b].item()
            edges = edge_index[b]  # [2, num_edges]
            
            # ğŸ”§ ä¿®å¤ï¼šè¿‡æ»¤æ‰ padding çš„è¾¹
            valid_mask = edges[0] >= 0
            
            # æ‰¾åˆ°åŒ…å«è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰è¾¹ï¼ˆåªè®¡ç®—ä¸€åŠï¼Œå› ä¸ºæ˜¯æ— å‘å›¾ï¼‰
            edge_mask = valid_mask & ((edges[0] == node_idx) | (edges[1] == node_idx)) & (edges[0] < edges[1])
            edge_indices = edge_mask.nonzero(as_tuple=True)[0]
            
            # æ ‡è®°è¿™äº›è¾¹ä¸ºå·²è¦†ç›–
            if len(edge_indices) > 0:
                covered_edges[b, edge_indices] = True
        
        return covered_edges
    
    def _set_task_data(self, task, edge_index, nodes_weight, td, idx):
        """è®¾ç½® MVCTask æ•°æ®"""
        task.from_data(
            nodes_num=self.num_nodes,
            edge_index=edge_index,
            nodes_weight=nodes_weight if self.node_weighted else None
        )
        
        if "selected" in td:
            solution = td["selected"][idx].cpu().numpy().astype(np.int32)
            task.sol = solution
            try:
                task.obj_val = task.evaluate(solution)
            except:
                pass
    
    @staticmethod
    def render(td: TensorDict, actions=None, ax=None):
        """å¯è§†åŒ–"""
        import matplotlib.pyplot as plt
        import networkx as nx
        
        if ax is None:
            _, ax = plt.subplots(figsize=(8, 8))
        
        edge_index = td["edge_index"][0].cpu().numpy()
        selected = td.get("selected", None)
        if selected is not None:
            selected = selected[0].cpu().numpy()
        
        G = nx.Graph()
        G.add_nodes_from(range(td["nodes_num"][0].item()))
        edges = [(edge_index[0, i], edge_index[1, i]) 
                 for i in range(edge_index.shape[1]) if edge_index[0, i] < edge_index[1, i]]
        G.add_edges_from(edges)
        
        pos = nx.spring_layout(G, k=1, iterations=50)
        
        if selected is not None:
            node_colors = ['red' if selected[i] else 'lightblue' 
                          for i in range(len(G.nodes()))]
            title = f"MVC Solution (Size: {selected.sum()})"
        else:
            node_colors = 'lightblue'
            title = "MVC Problem Instance"
        
        nx.draw(G, pos, node_color=node_colors, with_labels=True, 
               node_size=500, font_size=10, font_weight='bold', ax=ax)
        ax.set_title(title)


class MCLEnvWrapper(ML4COGraphWrapper):
    """
    Maximum Clique (MCL) Environment Wrapper
    
    ç›®æ ‡ï¼šæ‰¾åˆ°æœ€å¤§çš„å›¢ï¼ˆå®Œå…¨å­å›¾ï¼Œä»»æ„ä¸¤ä¸ªèŠ‚ç‚¹éƒ½ç›¸é‚»ï¼‰
    """
    
    name = "mcl"
    
    def __init__(
        self,
        num_nodes: int = 50,
        graph_type: str = 'erdos_renyi',
        edge_prob: float = 0.15,
        node_weighted: bool = False,
        **kwargs
    ):
        from ml4co_kit.task.graph.mcl import MClTask  # æ³¨æ„ï¼šæ˜¯ MClTask ä¸æ˜¯ MCLTask
        
        super().__init__(
            task_class=MClTask,
            task_params={'node_weighted': node_weighted},
            num_nodes=num_nodes,
            graph_type=graph_type,
            graph_params={'edge_prob': edge_prob},
            solver_class=None,
            **kwargs
        )
        
        self.node_weighted = node_weighted
    
    def _init_state(self, td: TensorDict, batch_size: int) -> TensorDict:
        """åˆå§‹åŒ–çŠ¶æ€ï¼ˆbatch_size å·²ç»æ˜¯æ•´æ•°ï¼‰"""
        # batch_size å·²ç»åœ¨ reset() ä¸­æ ‡å‡†åŒ–ä¸ºæ•´æ•°äº†
        
        td.update({
            "selected": torch.zeros(
                batch_size, self.num_nodes, 
                dtype=torch.bool, 
                device=self.device
            ),
            "available": torch.ones(
                batch_size, self.num_nodes, 
                dtype=torch.bool, 
                device=self.device
            ),
            "i": torch.zeros(batch_size, dtype=torch.int64, device=self.device),
            "done": torch.zeros(batch_size, dtype=torch.bool, device=self.device),
            "current_node": torch.zeros(batch_size, dtype=torch.long, device=self.device),
            "action_mask": torch.ones(
                batch_size, self.num_nodes,
                dtype=torch.bool,
                device=self.device
            ),
        })
        return td
    
    def _step(self, td: TensorDict) -> TensorDict:
        """æ‰§è¡Œä¸€æ­¥ï¼šé€‰æ‹©ä¸€ä¸ªèŠ‚ç‚¹åŠ å…¥å›¢"""
        selected_node = td["action"]
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šåªæ›´æ–°æœªå®Œæˆçš„å®ä¾‹
        prev_done = td["done"]
        
        # æ›´æ–° selectedï¼ˆåªæ›´æ–°æœªå®Œæˆçš„å®ä¾‹ï¼‰
        selected_mask = td["selected"].clone()
        if (~prev_done).any():
            selected_mask[~prev_done] = selected_mask[~prev_done].scatter(
                -1, 
                selected_node[~prev_done].unsqueeze(-1), 
                1
            )
        
        # æ›´æ–° availableï¼šåªä¿ç•™ä¸å½“å‰å›¢ä¸­æ‰€æœ‰èŠ‚ç‚¹éƒ½ç›¸é‚»çš„èŠ‚ç‚¹ï¼ˆåªå¯¹æœªå®Œæˆçš„å®ä¾‹ï¼‰
        available_mask = td["available"].clone()
        if (~prev_done).any():
            updated_available = self._update_available_for_clique(
                td["edge_index"][~prev_done],
                selected_mask[~prev_done],
                td["available"][~prev_done]
            )
            available_mask[~prev_done] = updated_available
        
        # è®¡ç®—å¥–åŠ±ï¼ˆåªå¯¹æœªå®Œæˆçš„å®ä¾‹ï¼‰
        reward = torch.zeros_like(prev_done, dtype=torch.float32)
        if (~prev_done).any():
            reward[~prev_done] = gather_by_index(
                td["nodes_weight"][~prev_done], 
                selected_node[~prev_done]
            )
        
        # æ£€æŸ¥å®Œæˆï¼ˆåˆå¹¶ä¹‹å‰çš„ done çŠ¶æ€ï¼‰
        done = prev_done | (~available_mask.any(-1))
        
        # å½“ done æ—¶ï¼Œä¸ºäº†é¿å… decoder é”™è¯¯ï¼Œæˆ‘ä»¬éœ€è¦è‡³å°‘ä¿ç•™ä¸€ä¸ªå¯ç”¨åŠ¨ä½œ
        action_mask = available_mask.clone()
        action_mask[done] = True  # å½“ done æ—¶ï¼Œè®¾ç½®ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä¸ºå¯ç”¨ï¼ˆè™šæ‹ŸåŠ¨ä½œï¼‰
        action_mask[done, 1:] = False  # åªä¿ç•™ç¬¬ä¸€ä¸ªèŠ‚ç‚¹å¯ç”¨
        
        td.update({
            "selected": selected_mask,
            "available": available_mask,
            "reward": reward,
            "done": done,
            "i": td["i"] + 1,
            "current_node": selected_node,
            "action_mask": action_mask,
        })
        
        return td
    
    def _update_available_for_clique(self, edge_index, selected, available):
        """æ›´æ–°å¯ç”¨èŠ‚ç‚¹ï¼šåªä¿ç•™ä¸æ‰€æœ‰å·²é€‰èŠ‚ç‚¹éƒ½ç›¸é‚»çš„èŠ‚ç‚¹"""
        batch_size = edge_index.shape[0]
        available = available.clone()
        
        for b in range(batch_size):
            selected_nodes = selected[b].nonzero(as_tuple=True)[0]
            if len(selected_nodes) == 0:
                continue
            
            edges = edge_index[b]
            # è¿‡æ»¤æ‰ padding çš„è¾¹
            valid_mask = edges[0] >= 0
            valid_edges = edges[:, valid_mask]
            
            # å¯¹æ¯ä¸ªå€™é€‰èŠ‚ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦ä¸æ‰€æœ‰å·²é€‰èŠ‚ç‚¹ç›¸é‚»
            for node in range(self.num_nodes):
                if not available[b, node]:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦ä¸æ‰€æœ‰å·²é€‰èŠ‚ç‚¹ç›¸é‚»
                is_connected_to_all = True
                for selected_node in selected_nodes:
                    # ğŸ”§ ä¿®å¤ï¼šå¯¹äºæ— å‘å›¾ï¼Œéœ€è¦æ£€æŸ¥ä¸¤ä¸ªæ–¹å‘
                    # æ–¹å‘1: (node, selected_node)
                    mask1 = (valid_edges[0] == node) & (valid_edges[1] == selected_node.item())
                    # æ–¹å‘2: (selected_node, node)
                    mask2 = (valid_edges[0] == selected_node.item()) & (valid_edges[1] == node)
                    
                    if not (mask1.any() or mask2.any()):
                        is_connected_to_all = False
                        break
                
                if not is_connected_to_all:
                    available[b, node] = False
        
        return available
    
    def _set_task_data(self, task, edge_index, nodes_weight, td, idx):
        """è®¾ç½® MCLTask æ•°æ®"""
        task.from_data(
            nodes_num=self.num_nodes,
            edge_index=edge_index,
            nodes_weight=nodes_weight if self.node_weighted else None
        )
        
        if "selected" in td:
            solution = td["selected"][idx].cpu().numpy().astype(np.int32)
            task.sol = solution
            try:
                task.obj_val = task.evaluate(solution)
            except:
                pass
    
    @staticmethod
    def render(td: TensorDict, actions=None, ax=None):
        """å¯è§†åŒ–"""
        import matplotlib.pyplot as plt
        import networkx as nx
        
        if ax is None:
            _, ax = plt.subplots(figsize=(8, 8))
        
        edge_index = td["edge_index"][0].cpu().numpy()
        selected = td.get("selected", None)
        if selected is not None:
            selected = selected[0].cpu().numpy()
        
        G = nx.Graph()
        G.add_nodes_from(range(td["nodes_num"][0].item()))
        edges = [(edge_index[0, i], edge_index[1, i]) 
                 for i in range(edge_index.shape[1]) if edge_index[0, i] < edge_index[1, i]]
        G.add_edges_from(edges)
        
        pos = nx.spring_layout(G, k=1, iterations=50)
        
        if selected is not None:
            node_colors = ['green' if selected[i] else 'lightblue' 
                          for i in range(len(G.nodes()))]
            title = f"Maximum Clique (Size: {selected.sum()})"
        else:
            node_colors = 'lightblue'
            title = "MCL Problem Instance"
        
        nx.draw(G, pos, node_color=node_colors, with_labels=True, 
               node_size=500, font_size=10, font_weight='bold', ax=ax)
        ax.set_title(title)


class MCUTEnvWrapper(ML4COGraphWrapper):
    """
    Maximum Cut (MCUT) Environment Wrapper
    
    ç›®æ ‡ï¼šå°†å›¾çš„èŠ‚ç‚¹åˆ†æˆä¸¤ä¸ªé›†åˆï¼Œæœ€å¤§åŒ–ä¸¤é›†åˆä¹‹é—´çš„è¾¹æ•°
    """
    
    name = "mcut"
    
    def __init__(
        self,
        num_nodes: int = 50,
        graph_type: str = 'erdos_renyi',
        edge_prob: float = 0.15,
        edge_weighted: bool = False,
        **kwargs
    ):
        from ml4co_kit.task.graph.mcut import MCutTask  # æ³¨æ„ï¼šæ˜¯ MCutTask ä¸æ˜¯ MCUTTask
        
        super().__init__(
            task_class=MCutTask,
            task_params={'edge_weighted': edge_weighted},
            num_nodes=num_nodes,
            graph_type=graph_type,
            graph_params={'edge_prob': edge_prob},
            solver_class=None,
            **kwargs
        )
        
        self.edge_weighted = edge_weighted
    
    def _generate_graph(self) -> Tuple[np.ndarray, Optional[np.ndarray]]:
        """ç”Ÿæˆå›¾ï¼ˆè¦†ç›–çˆ¶ç±»æ–¹æ³•ä»¥æ”¯æŒè¾¹æƒé‡ï¼‰"""
        edge_index, _ = super()._generate_graph()
        
        # ç”Ÿæˆè¾¹æƒé‡
        if self.edge_weighted:
            num_edges = edge_index.shape[1]
            edges_weight = np.random.rand(num_edges).astype(np.float32)
        else:
            edges_weight = None
        
        return edge_index, edges_weight
    
    def generate_data(self, batch_size) -> TensorDict:
        """ç”Ÿæˆæ•°æ®ï¼ˆè¦†ç›–ä»¥æ”¯æŒè¾¹æƒé‡ï¼‰"""
        # å¤„ç†å„ç§ batch_size æ ¼å¼
        if isinstance(batch_size, (tuple, list)):
            batch_size = batch_size[0]
        if isinstance(batch_size, torch.Tensor):
            batch_size = batch_size.item()
        batch_size = int(batch_size)
        
        edge_indices = []
        edges_weights = []
        edge_nums = []
        
        for _ in range(batch_size):
            edge_index, edges_weight = self._generate_graph()
            edge_indices.append(torch.from_numpy(edge_index).long())
            edge_nums.append(edge_index.shape[1])
            
            if edges_weight is not None:
                edges_weights.append(torch.from_numpy(edges_weight).float())
            else:
                num_edges = edge_index.shape[1]
                edges_weights.append(torch.ones(num_edges, dtype=torch.float32))
        
        # Pad to same length
        max_edges = max(edge_nums)
        padded_edge_indices = []
        padded_edges_weights = []
        
        for edge_idx, edge_weight, num_edges in zip(edge_indices, edges_weights, edge_nums):
            if num_edges < max_edges:
                # Pad edge_index with -1
                padding = torch.full((2, max_edges - num_edges), -1, dtype=torch.long)
                edge_idx = torch.cat([edge_idx, padding], dim=1)
                # Pad edge_weight with 0
                weight_padding = torch.zeros(max_edges - num_edges, dtype=torch.float32)
                edge_weight = torch.cat([edge_weight, weight_padding])
            padded_edge_indices.append(edge_idx)
            padded_edges_weights.append(edge_weight)
        
        td = TensorDict({
            "edge_index": torch.stack(padded_edge_indices).to(self.device),
            "edges_weight": torch.stack(padded_edges_weights).to(self.device),
            "nodes_num": torch.full((batch_size,), self.num_nodes, 
                                   dtype=torch.long, device=self.device),
            "edge_nums": torch.tensor(edge_nums, dtype=torch.long, device=self.device)
        }, batch_size=[batch_size])
        
        return td
    
    def _init_state(self, td: TensorDict, batch_size: int) -> TensorDict:
        """åˆå§‹åŒ–çŠ¶æ€ï¼ˆbatch_size å·²ç»æ˜¯æ•´æ•°ï¼‰"""
        # batch_size å·²ç»åœ¨ reset() ä¸­æ ‡å‡†åŒ–ä¸ºæ•´æ•°äº†
        
        # partition: 0 æˆ– 1ï¼Œè¡¨ç¤ºèŠ‚ç‚¹å±äºå“ªä¸ªåˆ†åŒº
        td.update({
            "partition": torch.zeros(
                batch_size, self.num_nodes, 
                dtype=torch.long, 
                device=self.device
            ),
            "i": torch.zeros(batch_size, dtype=torch.int64, device=self.device),
        })
        return td
    
    def _step(self, td: TensorDict) -> TensorDict:
        """æ‰§è¡Œä¸€æ­¥ï¼šå°†ä¸€ä¸ªèŠ‚ç‚¹åˆ†é…åˆ°æŸä¸ªåˆ†åŒº"""
        # action å¯ä»¥æ˜¯èŠ‚ç‚¹ç´¢å¼•ï¼Œæˆ–è€… (èŠ‚ç‚¹ç´¢å¼•, åˆ†åŒºç¼–å·)
        node_idx = td["action"]
        
        # ç®€åŒ–ï¼šå°†èŠ‚ç‚¹åˆ†é…åˆ°åˆ†åŒº1ï¼Œå…¶ä½™åœ¨åˆ†åŒº0
        partition = td["partition"].clone()
        partition.scatter_(-1, node_idx.unsqueeze(-1), 1)
        
        # è®¡ç®—å½“å‰çš„ cut å€¼ï¼ˆè·¨åˆ†åŒºçš„è¾¹æƒé‡å’Œï¼‰
        cut_value = self._calculate_cut(td["edge_index"], td["edges_weight"], partition)
        reward = cut_value - td.get("prev_cut", torch.zeros_like(cut_value))
        
        # æ£€æŸ¥å®Œæˆï¼ˆæ‰€æœ‰èŠ‚ç‚¹éƒ½å·²åˆ†é…ï¼‰
        done = td["i"] >= self.num_nodes - 1
        
        td.update({
            "partition": partition,
            "reward": reward,
            "prev_cut": cut_value,
            "done": done,
            "i": td["i"] + 1,
        })
        
        return td
    
    def _calculate_cut(self, edge_index, edges_weight, partition):
        """è®¡ç®— cut å€¼"""
        batch_size = edge_index.shape[0]
        cut_values = torch.zeros(batch_size, device=self.device)
        
        for b in range(batch_size):
            edges = edge_index[b]  # [2, num_edges]
            weights = edges_weight[b]
            part = partition[b]
            
            # åªè®¡ç®—ä¸€åŠçš„è¾¹ï¼ˆæ— å‘å›¾ï¼‰
            for e in range(edges.shape[1]):
                if edges[0, e] < edges[1, e]:  # é¿å…é‡å¤è®¡æ•°
                    u, v = edges[0, e].item(), edges[1, e].item()
                    if part[u] != part[v]:  # è·¨åˆ†åŒºçš„è¾¹
                        cut_values[b] += weights[e]
        
        return cut_values
    
    def _set_task_data(self, task, edge_index, nodes_weight, td, idx):
        """è®¾ç½® MCUTTask æ•°æ®"""
        edges_weight = td["edges_weight"][idx].cpu().numpy() if self.edge_weighted else None
        
        task.from_data(
            nodes_num=self.num_nodes,
            edge_index=edge_index,
            edges_weight=edges_weight
        )
        
        if "partition" in td:
            solution = td["partition"][idx].cpu().numpy().astype(np.int32)
            task.sol = solution
            try:
                task.obj_val = task.evaluate(solution)
            except:
                pass
    
    @staticmethod
    def render(td: TensorDict, actions=None, ax=None):
        """å¯è§†åŒ–"""
        import matplotlib.pyplot as plt
        import networkx as nx
        
        if ax is None:
            _, ax = plt.subplots(figsize=(8, 8))
        
        edge_index = td["edge_index"][0].cpu().numpy()
        partition = td.get("partition", None)
        if partition is not None:
            partition = partition[0].cpu().numpy()
        
        G = nx.Graph()
        G.add_nodes_from(range(td["nodes_num"][0].item()))
        edges = [(edge_index[0, i], edge_index[1, i]) 
                 for i in range(edge_index.shape[1]) if edge_index[0, i] < edge_index[1, i]]
        G.add_edges_from(edges)
        
        pos = nx.spring_layout(G, k=1, iterations=50)
        
        if partition is not None:
            node_colors = ['salmon' if partition[i] == 0 else 'lightgreen' 
                          for i in range(len(G.nodes()))]
            title = "Maximum Cut Solution"
        else:
            node_colors = 'lightblue'
            title = "MCUT Problem Instance"
        
        nx.draw(G, pos, node_color=node_colors, with_labels=True, 
               node_size=500, font_size=10, font_weight='bold', ax=ax)
        ax.set_title(title)
