# MCTS可视化指南

## 📊 可视化脚本说明

提供了两个脚本来详细展示MCTS在TSP问题上的工作过程：

### 1. `visualize_mcts_steps.py` - 单步详细分析

**功能**: 展示MCTS一步决策的完整过程，包括：
- 每次simulation的详细路径
- Selection阶段的UCB计算
- Expansion阶段的节点扩展
- Backpropagation的值传播
- 最终的动作选择

**适合**: 深入理解MCTS算法原理

**运行**:
```bash
cd /root/autodl-tmp/rl4co-urban
python visualize_mcts_steps.py
```

**输出示例**:
```
============================================================
模拟 1/5
============================================================

[深度 0] Selection: 选择最佳子节点
Node Info:
  - Visit count: 0
  - Value sum: 0.0000
  - Average value: 0.0000
  - Children: 0
  - Expanded: False

[深度 0] Expansion: 扩展节点
  评估结果:
    - 估计值: -5.2341
    - 有效动作: [0, 1, 2, 3, 4]
    - 动作概率:
      动作 0: 0.200
      动作 1: 0.200
      动作 2: 0.200
      动作 3: 0.200
      动作 4: 0.200
  → 创建了 5 个子节点

[Backpropagation] 回传值: -5.2341
  路径: root

...

搜索完成 - 根节点统计
============================================================

根节点被访问 5 次
所有子节点的访问统计:

动作     访问次数      平均值        先验概率    
--------------------------------------------------
2        2            -4.5123      0.200       
1        1            -5.8901      0.200       
3        1            -6.1234      0.200       
0        1            -5.4567      0.200       

最终决策: 选择动作 2 (访问次数最多)
```

### 2. `visualize_mcts_full.py` - 完整求解过程

**功能**: 展示MCTS求解完整TSP问题的过程，包括：
- 每一步的状态信息
- 可访问城市列表
- 搜索统计（访问次数、访问率等）
- 动作选择及其理由
- 最终的完整路径和总距离

**适合**: 观察MCTS的实际求解效果

**运行**:
```bash
cd /root/autodl-tmp/rl4co-urban
python visualize_mcts_full.py
```

**输出示例**:
```
============================================================
第 1 步决策
============================================================

当前状态:
  - 当前位置: 城市 0
  - 可访问城市: [0, 1, 2, 3, 4]
  - 已访问: 0 / 5 城市

运行MCTS搜索 (10 次模拟)...

搜索统计:
  根节点访问次数: 10

  候选动作统计:
  动作     访问次数      访问率    平均值        先验    
  ------------------------------------------------------------
  3        4            40.0%     -3.4567      0.200       ← 选择
  1        3            30.0%     -4.1234      0.200       
  2        2            20.0%     -4.8901      0.200       
  4        1            10.0%     -5.5678      0.200       

→ 选择动作: 3 (从城市 0 到城市 3)
  距离: 0.4123

============================================================
第 2 步决策
============================================================
...

求解完成
============================================================

完整路径: 0 → 3 → 1 → 4 → 2

总路径长度: 4.5678
```

## 🎯 关键输出说明

### UCB分数计算

```
Action 2:
  Q(s,a) = -15.234/5 = -3.047
  U(s,a) = 1.0 * 0.200 * sqrt(10) / (1+5)
         = 1.0 * 0.200 * 3.162 / 6
         = 0.105
  Score  = -3.047 + 0.105 = -2.942
  (visits: 5, prior: 0.200)
```

**说明**:
- **Q(s,a)**: 平均回报，越大越好（TSP是负值，越接近0越好）
- **U(s,a)**: 探索奖励，访问少的动作获得更高奖励
- **Score**: 总分 = 利用 + 探索

### 访问统计表

```
动作     访问次数      访问率    平均值        先验    
------------------------------------------------------------
3        4            40.0%     -3.4567      0.200       ← 选择
1        3            30.0%     -4.1234      0.200       
2        2            20.0%     -4.8901      0.200       
```

**说明**:
- **访问次数**: 该动作在MCTS中被模拟的次数
- **访问率**: 占总模拟次数的百分比
- **平均值**: 该动作的平均回报
- **先验**: 初始概率（无policy时均匀分布）
- **← 选择**: 最终选择的动作（通常是访问次数最多的）

## 🔧 自定义参数

### 修改问题规模

```python
# 在脚本中找到这行
problem_size = 5  # 改为 10, 20 等

env = TSPEnv(generator_params={'num_loc': problem_size})
```

### 调整MCTS参数

```python
mcts = MCTSModel(
    env=env,
    policy=None,
    num_simulations=10,  # 模拟次数: 增加→质量更好但更慢
    c_puct=1.0,         # 探索常数: 增加→更多探索
    temperature=0.0,     # 温度: 0=贪婪, >0=随机
    device='cpu'
)
```

### 参数效果对比

| 参数 | 较小值 | 较大值 |
|------|--------|--------|
| `num_simulations` | 快速但质量低 | 慢但质量高 |
| `c_puct` | 更多利用（选已知好的） | 更多探索（尝试新的） |
| `temperature` | 确定性选择 | 随机性选择 |

## 📈 实验建议

### 1. 观察探索vs利用

```bash
# 运行多次，观察不同c_puct的效果
# 在脚本中修改 c_puct = 0.5, 1.0, 2.0
python visualize_mcts_full.py
```

**预期**: c_puct越大，访问分布越均匀

### 2. 模拟次数的影响

```bash
# 对比 num_simulations = 5, 10, 50
python visualize_mcts_full.py
```

**预期**: 模拟次数越多，置信度越高，选择越准确

### 3. 问题规模缩放

```bash
# 测试 problem_size = 5, 10, 15, 20
python visualize_mcts_full.py
```

**预期**: 问题越大，需要更多模拟次数

## 💡 观察要点

### 1. Selection阶段
- 观察UCB公式如何平衡探索和利用
- 访问少的节点获得更高的探索奖励

### 2. Expansion阶段
- 首次访问节点时创建所有子节点
- 每个子节点获得先验概率

### 3. Backpropagation阶段
- 值如何从叶节点传播到根节点
- 所有路径上的节点都被更新

### 4. 最终选择
- 通常选择访问次数最多的动作
- 这代表了MCTS的"集体智慧"

## 🎓 深入理解

### MCTS的核心思想

1. **蒙特卡洛**: 通过随机采样估计值
2. **树搜索**: 有选择性地探索搜索空间
3. **UCB**: 平衡已知好的（利用）和未知的（探索）

### 为什么MCTS有效？

- **自适应**: 自动聚焦在有希望的区域
- **无偏**: 给所有动作公平的机会
- **渐进最优**: 模拟次数趋于无穷时收敛到最优

### 局限性

- **计算密集**: 每步需要多次模拟
- **串行**: 难以并行化（但可以用虚拟损失）
- **启发式评估**: 当前使用简单的rollout，更好的方法是值网络

## 🚀 进阶使用

### 结合神经网络

```python
from rl4co.models.zoo.am import AttentionModelPolicy

policy = AttentionModelPolicy(env_name='tsp')
mcts = MCTSModel(env=env, policy=policy, num_simulations=100)
```

**效果**: Policy提供更好的先验概率和值估计

### 保存可视化结果

```python
# 重定向输出到文件
python visualize_mcts_full.py > mcts_output.txt
```

### 对比不同方法

```python
# 1. 纯贪婪
# 2. 纯MCTS
# 3. MCTS + Policy
# 观察质量差异
```

## 📚 相关资源

- **MCTS原理**: `MCTS_IMPLEMENTATION_SUMMARY.md`
- **Bug修复记录**: `MCTS_FIXES_SUMMARY.md`
- **使用文档**: `rl4co/models/zoo/MCTS/README.md`
- **快速开始**: `rl4co/models/zoo/MCTS/QUICKSTART.md`

---

**提示**: 这些可视化脚本是学习MCTS的绝佳工具！通过观察实际运行过程，能更深入理解算法细节。
